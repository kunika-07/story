{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tnj1wk_unK2z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.rottentomatoes.com/browse/movies_at_home/sort:popular?page=16'\n",
        "response = requests.get(url)\n",
        "print('The response that we got back from the URL is', response.status_code)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8w-YFuYngai",
        "outputId": "7d83d545-18f6-47c0-e14c-bd6f359ab879"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The response that we got back from the URL is 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text,'html.parser')\n",
        "html = soup.find_all('div')"
      ],
      "metadata": {
        "id": "TZSO77d7nslo"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_tags = soup.find_all('a', {'data-track': 'scores', 'data-qa': 'discovery-media-list-item-caption'})\n",
        "orignal ='https://www.rottentomatoes.com'\n",
        "href_tags=  [a['href'] for a in a_tags]\n",
        "urls=[]\n",
        "for ht in href_tags:\n",
        "  x=orignal+ht\n",
        "  urls.append(x)\n",
        "print(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7PQmKEa4XmZ",
        "outputId": "befadfb3-c8e4-4fd8-c6a7-d63a0a92c252"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.rottentomatoes.com/m/godzilla_minus_one', 'https://www.rottentomatoes.com/m/hit_man_2023', 'https://www.rottentomatoes.com/m/the_fall_guy_2024', 'https://www.rottentomatoes.com/m/atlas_2024', 'https://www.rottentomatoes.com/m/civil_war_2024', 'https://www.rottentomatoes.com/m/the_first_omen', 'https://www.rottentomatoes.com/m/challengers_2024', 'https://www.rottentomatoes.com/m/the_last_stop_in_yuma_county', 'https://www.rottentomatoes.com/m/late_night_with_the_devil', 'https://www.rottentomatoes.com/m/the_strangers_chapter_1', 'https://www.rottentomatoes.com/m/mad_max_fury_road', 'https://www.rottentomatoes.com/m/tarot_2024', 'https://www.rottentomatoes.com/m/am_i_ok', 'https://www.rottentomatoes.com/m/madame_web', 'https://www.rottentomatoes.com/m/what_you_wish_for', 'https://www.rottentomatoes.com/m/the_ministry_of_ungentlemanly_warfare', 'https://www.rottentomatoes.com/m/the_idea_of_you', 'https://www.rottentomatoes.com/m/run_lola_run', 'https://www.rottentomatoes.com/m/bad_boys_for_life', 'https://www.rottentomatoes.com/m/godzilla_x_kong_the_new_empire', 'https://www.rottentomatoes.com/m/dune_part_two', 'https://www.rottentomatoes.com/m/new_life_2023', 'https://www.rottentomatoes.com/m/immaculate_2024', 'https://www.rottentomatoes.com/m/back_to_black', 'https://www.rottentomatoes.com/m/cabrini', 'https://www.rottentomatoes.com/m/abigail_2024', 'https://www.rottentomatoes.com/m/anyone_but_you_2023', 'https://www.rottentomatoes.com/m/a_simple_favor', 'https://www.rottentomatoes.com/m/jim_henson_idea_man', 'https://www.rottentomatoes.com/m/the_iron_claw_2023', 'https://www.rottentomatoes.com/m/dark_waters_2019', 'https://www.rottentomatoes.com/m/unfrosted', 'https://www.rottentomatoes.com/m/monkey_man', 'https://www.rottentomatoes.com/m/the_boys_in_the_boat', 'https://www.rottentomatoes.com/m/boy_kills_world', 'https://www.rottentomatoes.com/m/the_beekeeper_2024', 'https://www.rottentomatoes.com/m/argylle', 'https://www.rottentomatoes.com/m/war_for_the_planet_of_the_apes', 'https://www.rottentomatoes.com/m/laroy_texas', 'https://www.rottentomatoes.com/m/the_hunger_games_the_ballad_of_songbirds_and_snakes', 'https://www.rottentomatoes.com/m/poor_things', 'https://www.rottentomatoes.com/m/leave_the_world_behind_2023', 'https://www.rottentomatoes.com/m/mother_of_the_bride_2024', 'https://www.rottentomatoes.com/m/infested_2023', 'https://www.rottentomatoes.com/m/all_of_us_strangers', 'https://www.rottentomatoes.com/m/poolman', 'https://www.rottentomatoes.com/m/upgrade_2018', 'https://www.rottentomatoes.com/m/x_2022', 'https://www.rottentomatoes.com/m/kung_fu_panda_4', 'https://www.rottentomatoes.com/m/the_lord_of_the_rings_the_fellowship_of_the_ring', 'https://www.rottentomatoes.com/m/1917_2019', 'https://www.rottentomatoes.com/m/american_fiction', 'https://www.rottentomatoes.com/m/a_million_ways_to_die_in_the_west', 'https://www.rottentomatoes.com/m/five_nights_at_freddys', 'https://www.rottentomatoes.com/m/sting', 'https://www.rottentomatoes.com/m/arcadian', 'https://www.rottentomatoes.com/m/stopmotion', 'https://www.rottentomatoes.com/m/ferrari_2023', 'https://www.rottentomatoes.com/m/dream_scenario', 'https://www.rottentomatoes.com/m/anatomy_of_a_fall', 'https://www.rottentomatoes.com/m/ghostbusters_frozen_empire', 'https://www.rottentomatoes.com/m/love_lies_bleeding_2024', 'https://www.rottentomatoes.com/m/exhuma', 'https://www.rottentomatoes.com/m/dawn_of_the_planet_of_the_apes', 'https://www.rottentomatoes.com/m/the_bricklayer_2023', 'https://www.rottentomatoes.com/m/talk_to_me_2023', 'https://www.rottentomatoes.com/m/the_gentlemen', 'https://www.rottentomatoes.com/m/the_outfit_2022', 'https://www.rottentomatoes.com/m/the_crow', 'https://www.rottentomatoes.com/m/dune_2021', 'https://www.rottentomatoes.com/m/the_old_oak', 'https://www.rottentomatoes.com/m/the_little_things_2021', 'https://www.rottentomatoes.com/m/the_judge_2014', 'https://www.rottentomatoes.com/m/inside_out_2015', 'https://www.rottentomatoes.com/m/his_house', 'https://www.rottentomatoes.com/m/may_december', 'https://www.rottentomatoes.com/m/the_holdovers', 'https://www.rottentomatoes.com/m/the_zone_of_interest', 'https://www.rottentomatoes.com/m/the_blue_angels', 'https://www.rottentomatoes.com/m/oppenheimer_2023', 'https://www.rottentomatoes.com/m/the_peanut_butter_falcon', 'https://www.rottentomatoes.com/m/bad_boys_ii', 'https://www.rottentomatoes.com/m/arthur_the_king', 'https://www.rottentomatoes.com/m/millers_girl', 'https://www.rottentomatoes.com/m/bullet_train_2022', 'https://www.rottentomatoes.com/m/road_house', 'https://www.rottentomatoes.com/m/damsel_2023', 'https://www.rottentomatoes.com/m/the_killer_2023', 'https://www.rottentomatoes.com/m/venom_2018', 'https://www.rottentomatoes.com/m/reptile_2023', 'https://www.rottentomatoes.com/m/rebel_moon_part_1_a_child_of_fire', 'https://www.rottentomatoes.com/m/in_the_land_of_saints_and_sinners', 'https://www.rottentomatoes.com/m/killers_of_the_flower_moon', 'https://www.rottentomatoes.com/m/bionic', 'https://www.rottentomatoes.com/m/divergent', 'https://www.rottentomatoes.com/m/backspot', 'https://www.rottentomatoes.com/m/mean_girls_2024', 'https://www.rottentomatoes.com/m/past_lives', 'https://www.rottentomatoes.com/m/spaceman_2024', 'https://www.rottentomatoes.com/m/the_wonderful_story_of_henry_sugar', 'https://www.rottentomatoes.com/m/pearl_2022', 'https://www.rottentomatoes.com/m/moviepass_moviecrash', 'https://www.rottentomatoes.com/m/300_rise_of_an_empire', 'https://www.rottentomatoes.com/m/wish_2023', 'https://www.rottentomatoes.com/m/the_gift_2015', 'https://www.rottentomatoes.com/m/interstellar_2014', 'https://www.rottentomatoes.com/m/cold_copy', 'https://www.rottentomatoes.com/m/wonka', 'https://www.rottentomatoes.com/m/the_marvels', 'https://www.rottentomatoes.com/m/how_to_rob_a_bank_2024', 'https://www.rottentomatoes.com/m/wicked_little_letters', 'https://www.rottentomatoes.com/m/one_life', 'https://www.rottentomatoes.com/m/rebel_moon_part_two_the_scargiver', 'https://www.rottentomatoes.com/m/no_hard_feelings_2023', 'https://www.rottentomatoes.com/m/star_wars_the_last_jedi', 'https://www.rottentomatoes.com/m/when_evil_lurks', 'https://www.rottentomatoes.com/m/eileen', 'https://www.rottentomatoes.com/m/on_the_basis_of_sex', 'https://www.rottentomatoes.com/m/hereditary', 'https://www.rottentomatoes.com/m/knox_goes_away', 'https://www.rottentomatoes.com/m/where_the_crawdads_sing', 'https://www.rottentomatoes.com/m/bob_marley_one_love']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSNJRqRYecQ8",
        "outputId": "518d4dc7-2b44-4f5d-b374-afffa6129983"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pymongo import MongoClient\n",
        "\n",
        "class Review:\n",
        "    def __init__(self, reviewer_name, profession, review_content):\n",
        "        self.reviewer_name = reviewer_name\n",
        "        self.profession = profession\n",
        "        self.review_content = review_content\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"reviewer_name\": self.reviewer_name,\n",
        "            \"profession\": self.profession,\n",
        "            \"review_content\": self.review_content\n",
        "        }\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Review(reviewer_name='{self.reviewer_name}', profession='{self.profession}', review_content='{self.review_content}')\"\n",
        "\n",
        "class Movie:\n",
        "    def __init__(self, movie_name):\n",
        "        self.movie_name = movie_name\n",
        "        self.scores = {'critics': None, 'audience': None}\n",
        "        self.reviews = []\n",
        "\n",
        "    def add_review(self, review):\n",
        "        self.reviews.append(review)\n",
        "\n",
        "    def set_scores(self, critics_score, audience_score):\n",
        "        self.scores['critics'] = critics_score\n",
        "        self.scores['audience'] = audience_score\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            \"movie_name\": self.movie_name,\n",
        "            \"scores\": self.scores,\n",
        "            \"reviews\": [review.to_dict() for review in self.reviews]\n",
        "        }\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Movie(movie_name='{self.movie_name}', scores={self.scores}, reviews={self.reviews})\"\n",
        "\n",
        "def fetch_reviews_from_view_all(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "    review_cards = soup.select('review-card-critic')\n",
        "\n",
        "    for card in review_cards:\n",
        "        reviewer_name = card.select_one('rt-link[slot=\"displayName\"] rt-text').text.strip()\n",
        "        profession = card.select_one('rt-link[slot=\"publicationName\"] rt-text').text.strip()\n",
        "        review_content = card.select_one('drawer-more[slot=\"reviewQuote\"] rt-text').text.strip()\n",
        "\n",
        "        review = Review(reviewer_name, profession, review_content)\n",
        "        reviews.append(review)\n",
        "\n",
        "    return reviews\n",
        "\n",
        "def fetch_movie_data(urls):\n",
        "    movies = []\n",
        "\n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Assuming the movie name is in an <h1> tag with class 'unset'\n",
        "        movie_name = soup.select_one('h1.unset span').text\n",
        "        movie = Movie(movie_name)\n",
        "\n",
        "        # Extract the initial reviews present on the movie's main page\n",
        "        review_cards = soup.select('review-card-critic')\n",
        "        for card in review_cards:\n",
        "            reviewer_name = card.select_one('rt-link[slot=\"displayName\"] rt-text').text.strip()\n",
        "            profession = card.select_one('rt-link[slot=\"publicationName\"] rt-text').text.strip()\n",
        "            review_content = card.select_one('drawer-more[slot=\"reviewQuote\"] rt-text').text.strip()\n",
        "            review = Review(reviewer_name, profession, review_content)\n",
        "            movie.add_review(review)\n",
        "\n",
        "        # Extract \"View All\" link\n",
        "        view_all_link = soup.select_one('.header-wrap rt-link[href]')\n",
        "        if view_all_link:\n",
        "            view_all_url = view_all_link['href']\n",
        "            # Construct full URL if it's a relative path\n",
        "            full_reviews_url = f\"https://www.rottentomatoes.com{view_all_url}\" if view_all_url.startswith('/') else view_all_url\n",
        "            # Fetch all reviews from the \"View All\" page\n",
        "            full_reviews = fetch_reviews_from_view_all(full_reviews_url)\n",
        "\n",
        "            for review in full_reviews:\n",
        "                movie.add_review(review)\n",
        "\n",
        "        # Extract scores\n",
        "        scores = soup.select('rt-text[size=\"1.375\"][theme=\"medium\"]')\n",
        "        if len(scores) >= 2:\n",
        "            critics_score = scores[0].text.strip()\n",
        "            audience_score = scores[1].text.strip()\n",
        "            movie.set_scores(critics_score, audience_score)\n",
        "\n",
        "        movies.append(movie)\n",
        "\n",
        "    return movies\n",
        "\n",
        "def upload_to_mongodb(movies, db_name='movie_reviews', collection_name='movies'):\n",
        "    # Connect to MongoDB\n",
        "    client = MongoClient('mongodb+srv://review123:review123@cluster0.73f4jpp.mongodb.net/')  # Change the connection string if necessary\n",
        "    db = client[db_name]\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    # Insert movie data into MongoDB\n",
        "    for movie in movies:\n",
        "        collection.insert_one(movie.to_dict())\n",
        "\n",
        "    print(f\"Uploaded {len(movies)} movies to MongoDB.\")\n",
        "\n",
        "\n",
        "\n",
        "# Fetch movie data\n",
        "movies = fetch_movie_data(urls)\n",
        "\n",
        "# Upload to MongoDB\n",
        "upload_to_mongodb(movies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpBsP8kZedjt",
        "outputId": "b8b078bf-294f-4a75-dfe9-97f8d399c4eb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded 122 movies to MongoDB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyppeteer\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOXafVoUpYmy",
        "outputId": "3899f299-b4c1-4a84-be8d-3162cc6cb980"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyppeteer\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.3 (from pyppeteer)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (2024.6.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (7.1.0)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer)\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (4.66.4)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.12.1)\n",
            "Installing collected packages: appdirs, websockets, urllib3, pyee, pyppeteer\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed appdirs-1.4.4 pyee-11.1.0 pyppeteer-2.0.0 urllib3-1.26.18 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV9obuj1H3RA",
        "outputId": "2e0312d4-fe81-41b3-83b0-76c0a4140ef4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyppeteer beautifulsoup4 nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQk5kHQyJvjQ",
        "outputId": "41cb3d11-76a4-4a3b-f0d9-519c40aca751"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyppeteer in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (2024.6.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (7.1.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (11.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (4.66.4)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (1.26.18)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (10.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.12.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pyppeteer-install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUG0PcMPLAAv",
        "outputId": "64d031b2-4f11-4b23-f2d2-8d5cf7e1e3d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chromium is already installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pyppeteer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXv4NMI2LHQk",
        "outputId": "b27aaf2d-686d-41f0-932b-b64d55c6b64b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyppeteer in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (2024.6.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (7.1.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (11.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (4.66.4)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (1.26.18)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer) (10.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.12.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from pyppeteer import launch\n",
        "from bs4 import BeautifulSoup\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        # Launch the browser and open a new blank page\n",
        "        browser = await launch(headless=True)\n",
        "        page = await browser.newPage()\n",
        "\n",
        "        # Navigate the page to the target URL\n",
        "        url = 'https://www.rottentomatoes.com/browse/movies_at_home/sort:popular'  # Replace with your actual URL\n",
        "        await page.goto(url)\n",
        "\n",
        "        # Function to extract movie titles\n",
        "        async def extract_movies():\n",
        "            content = await page.content()\n",
        "            soup = BeautifulSoup(content, 'html.parser')\n",
        "            movie_elements = soup.select('.movie-title-class')  # Replace with actual selector\n",
        "            return [element.get_text(strip=True) for element in movie_elements]\n",
        "\n",
        "        # Extract initially loaded movies\n",
        "        movies = await extract_movies()\n",
        "\n",
        "        # Click the \"Load More\" button to load more movies\n",
        "        load_more_button_selector = 'button[data-qa=\"dlp-load-more-button\"]'\n",
        "        await page.waitForSelector(load_more_button_selector)\n",
        "        await page.click(load_more_button_selector)\n",
        "\n",
        "        # Wait for new movies to load\n",
        "        await page.waitForTimeout(2000)  # Adjust based on loading time or use a more specific wait condition\n",
        "\n",
        "        # Extract additional movies\n",
        "        more_movies = await extract_movies()\n",
        "        movies.extend(more_movies)\n",
        "\n",
        "        # Print all extracted movies\n",
        "        print('Extracted movies:', movies)\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'An error occurred: {e}')\n",
        "        if 'browser' in locals():\n",
        "            await browser.close()\n",
        "\n",
        "# Run the main function\n",
        "asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw22wyTLLNf2",
        "outputId": "3a47519c-00c2-479a-f10c-80c8aa13f52f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: Browser closed unexpectedly:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from pyppeteer import launch\n",
        "from bs4 import BeautifulSoup\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio to patch the event loop\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def main():\n",
        "    browser = None  # Initialize browser variable outside try block\n",
        "\n",
        "    try:\n",
        "        # Launch the browser and open a new blank page\n",
        "        browser = await launch(headless=True)\n",
        "        page = await browser.newPage()\n",
        "\n",
        "        # Navigate the page to the target URL\n",
        "        url = 'https://www.rottentomatoes.com/browse/movies_at_home/sort:popular'\n",
        "        await page.goto(url)\n",
        "\n",
        "        # Function to extract movie titles\n",
        "        async def extract_movies():\n",
        "            content = await page.content()\n",
        "            soup = BeautifulSoup(content, 'html.parser')\n",
        "            movie_elements = soup.select('.movieTitle')  # Corrected selector\n",
        "            return [element.get_text(strip=True) for element in movie_elements]\n",
        "\n",
        "        # Extract initially loaded movies\n",
        "        movies = await extract_movies()\n",
        "\n",
        "        # Click the \"Load More\" button to load more movies\n",
        "        load_more_button_selector = 'button[data-qa=\"dlp-load-more-button\"]'\n",
        "        await page.waitForSelector(load_more_button_selector)\n",
        "        await page.click(load_more_button_selector)\n",
        "\n",
        "        # Wait for new movies to load\n",
        "        await page.waitForTimeout(5000)  # Increased wait time to 5 seconds\n",
        "\n",
        "        # Extract additional movies\n",
        "        more_movies = await extract_movies()\n",
        "        movies.extend(more_movies)\n",
        "\n",
        "        # Print all extracted movies\n",
        "        print('Extracted movies:', movies)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'An error occurred: {e}')\n",
        "\n",
        "    finally:\n",
        "        if browser:\n",
        "            await browser.close()\n",
        "\n",
        "# Run the main function\n",
        "asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na2ZM5xsLRQb",
        "outputId": "60faa066-a20e-40cb-bc49-965dac70bbed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: Browser closed unexpectedly:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MIIbQ8PtMlX7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}